{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed18c03-c22f-40af-94cd-300312e8c870",
   "metadata": {},
   "source": [
    "# CELL 1: DATA LOADING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b686698-1f51-465b-ab3d-b88bd1f1e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV: creditdb_train.csv, creditdb_test.csv\n",
      "Shapes -> train: (94908, 11)  test: (23727, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load creditdb_train / creditdb_test from CSV\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path.cwd().parent / \"data\"\n",
    "\n",
    "p_csv_train = data_dir / \"creditdb_train.csv\"\n",
    "p_csv_test  = data_dir / \"creditdb_test.csv\"\n",
    "\n",
    "if p_csv_train.exists() and p_csv_test.exists():\n",
    "    creditdb_train = pd.read_csv(p_csv_train)\n",
    "    creditdb_test  = pd.read_csv(p_csv_test)\n",
    "    print(\"Loaded CSV: creditdb_train.csv, creditdb_test.csv\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No encontré creditdb_train.csv o creditdb_test.csv en data/. Guarda los archivos desde el EDA primero.\")\n",
    "\n",
    "print(\"Shapes -> train:\", creditdb_train.shape, \" test:\", creditdb_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454157d-88cf-431b-97fc-0cac313a27b8",
   "metadata": {},
   "source": [
    "# CELL 2: QUICK CHECKS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7006bc83-6691-48bb-b8a8-36f981b81edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94908 entries, 0 to 94907\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   RevolvingUtilizationOfUnsecuredLines  94908 non-null  float64\n",
      " 1   age                                   94908 non-null  int64  \n",
      " 2   NumberOfTime30-59DaysPastDueNotWorse  94908 non-null  int64  \n",
      " 3   DebtRatio                             94908 non-null  float64\n",
      " 4   MonthlyIncome                         94908 non-null  float64\n",
      " 5   NumberOfOpenCreditLinesAndLoans       94908 non-null  int64  \n",
      " 6   NumberOfTimes90DaysLate               94908 non-null  int64  \n",
      " 7   NumberRealEstateLoansOrLines          94908 non-null  int64  \n",
      " 8   NumberOfTime60-89DaysPastDueNotWorse  94908 non-null  int64  \n",
      " 9   NumberOfDependents                    94908 non-null  float64\n",
      " 10  SeriousDlqin2yrs                      94908 non-null  bool   \n",
      "dtypes: bool(1), float64(4), int64(6)\n",
      "memory usage: 7.3 MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23727 entries, 0 to 23726\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   RevolvingUtilizationOfUnsecuredLines  23727 non-null  float64\n",
      " 1   age                                   23727 non-null  int64  \n",
      " 2   NumberOfTime30-59DaysPastDueNotWorse  23727 non-null  int64  \n",
      " 3   DebtRatio                             23727 non-null  float64\n",
      " 4   MonthlyIncome                         23727 non-null  float64\n",
      " 5   NumberOfOpenCreditLinesAndLoans       23727 non-null  int64  \n",
      " 6   NumberOfTimes90DaysLate               23727 non-null  int64  \n",
      " 7   NumberRealEstateLoansOrLines          23727 non-null  int64  \n",
      " 8   NumberOfTime60-89DaysPastDueNotWorse  23727 non-null  int64  \n",
      " 9   NumberOfDependents                    23727 non-null  float64\n",
      " 10  SeriousDlqin2yrs                      23727 non-null  bool   \n",
      "dtypes: bool(1), float64(4), int64(6)\n",
      "memory usage: 1.8 MB\n",
      "\n",
      "Distribución target (train):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs\n",
       "False    0.930111\n",
       "True     0.069889\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución target (test):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs\n",
       "False    0.930122\n",
       "True     0.069878\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen MonthlyIncome (train):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    94908.000000\n",
       "mean      6458.043547\n",
       "std       4338.584722\n",
       "min          1.000000\n",
       "25%       3500.000000\n",
       "50%       5458.000000\n",
       "75%       8333.000000\n",
       "max      25000.000000\n",
       "Name: MonthlyIncome, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen DebtRatio (train):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    94908.000000\n",
       "mean         0.376319\n",
       "std          0.415131\n",
       "min          0.000000\n",
       "25%          0.141308\n",
       "50%          0.291724\n",
       "75%          0.471787\n",
       "max          2.999627\n",
       "Name: DebtRatio, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick checks after loading the datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "creditdb_train.info()\n",
    "print('')\n",
    "creditdb_test.info()\n",
    "\n",
    "print(\"\\nDistribución target (train):\")\n",
    "display(creditdb_train['SeriousDlqin2yrs'].value_counts(normalize=True).rename(\"proportion\"))\n",
    "\n",
    "print(\"\\nDistribución target (test):\")\n",
    "display(creditdb_test['SeriousDlqin2yrs'].value_counts(normalize=True).rename(\"proportion\"))\n",
    "\n",
    "# Basic statistics for MonthlyIncome and DebtRatio (verify capping)\n",
    "print(\"\\nResumen MonthlyIncome (train):\")\n",
    "display(creditdb_train['MonthlyIncome'].describe())\n",
    "print(\"\\nResumen DebtRatio (train):\")\n",
    "display(creditdb_train['DebtRatio'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4caaf52-a3dd-444d-b2ad-aaff97247f65",
   "metadata": {},
   "source": [
    "# CELL 3: SPLITTING THE DATASETS FOR MODELING PURPOSES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ecf242-1fbe-4cea-a28f-272a19e33965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared datasets:\n",
      " RF -> X_train: (94908, 10)  y_train: (94908,)\n",
      " RF -> X_test:  (23727, 10)  y_test : (23727,)\n",
      " LR -> X_train: (94908, 10)  y_train: (94908,)\n",
      " LR -> X_test:  (23727, 10)  y_test : (23727,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X/y for RandomForest (unscaled) and LogisticRegression (MinMax-scaled, fit on train)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Basic checks and ensure target is Boolean\n",
    "if 'creditdb_train' not in globals() or 'creditdb_test' not in globals():\n",
    "    raise RuntimeError(\"No encuentro creditdb_train/creditdb_test en memoria. Carga los CSV primero.\")\n",
    "\n",
    "# Ensure SeriousDlqin2yrs is Boolean (if loaded as 0/1 from CSV)\n",
    "for df in (creditdb_train, creditdb_test):\n",
    "    if df['SeriousDlqin2yrs'].dtype != bool:\n",
    "        # convertir 0/1 a bool de forma segura\n",
    "        df['SeriousDlqin2yrs'] = df['SeriousDlqin2yrs'].astype(int).astype(bool)\n",
    "\n",
    "# 2) Prepare X/y for RandomForest (use columns as-is, without scaling)\n",
    "feature_cols_rf = [c for c in creditdb_train.columns if c != 'SeriousDlqin2yrs']\n",
    "X_train_rf = creditdb_train[feature_cols_rf].copy()\n",
    "y_train_rf = creditdb_train['SeriousDlqin2yrs'].copy()\n",
    "\n",
    "X_test_rf  = creditdb_test[feature_cols_rf].copy()\n",
    "y_test_rf  = creditdb_test['SeriousDlqin2yrs'].copy()\n",
    "\n",
    "# 3) Prepare X/y for LogisticRegression (MinMaxScaler fit on train\n",
    "# Select numeric columns for scaling (excluding the target)\n",
    "num_cols = creditdb_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'SeriousDlqin2yrs' in num_cols:\n",
    "    num_cols.remove('SeriousDlqin2yrs')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(creditdb_train[num_cols].values)   # fit solo en train (evita data leakage)\n",
    "\n",
    "# Transform and reconstruct scaled DataFrames (retain all original columns)\n",
    "scaled_train = creditdb_train.copy()\n",
    "scaled_test  = creditdb_test.copy()\n",
    "\n",
    "scaled_train[num_cols] = scaler.transform(creditdb_train[num_cols].values)\n",
    "scaled_test[num_cols]  = scaler.transform(creditdb_test[num_cols].values)\n",
    "\n",
    "# Create X/y for LR (use the same set of features as in RF for comparability)\n",
    "feature_cols_lr = [c for c in scaled_train.columns if c != 'SeriousDlqin2yrs']\n",
    "X_train_lr = scaled_train[feature_cols_lr].copy()\n",
    "y_train_lr = scaled_train['SeriousDlqin2yrs'].copy()\n",
    "\n",
    "X_test_lr  = scaled_test[feature_cols_lr].copy()\n",
    "y_test_lr  = scaled_test['SeriousDlqin2yrs'].copy()\n",
    "\n",
    "# 4) Summary\n",
    "print(\"Prepared datasets:\")\n",
    "print(\" RF -> X_train:\", X_train_rf.shape, \" y_train:\", y_train_rf.shape)\n",
    "print(\" RF -> X_test: \", X_test_rf.shape,  \" y_test :\", y_test_rf.shape)\n",
    "print(\" LR -> X_train:\", X_train_lr.shape, \" y_train:\", y_train_lr.shape)\n",
    "print(\" LR -> X_test: \", X_test_lr.shape,  \" y_test :\", y_test_lr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057b582-dca7-4e45-8eee-30d4d3583db5",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# MODEL TRAINING."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b929ef-ef9a-4029-bf42-755a78fa0423",
   "metadata": {},
   "source": [
    "# CELL 4: LOGISTIC REGRESSION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d20b02c-d462-43b8-9343-d07f6d8c7791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (baseline) — Test results\n",
      " Recall  (positive class): 0.6604\n",
      " Precision(positive class): 0.1624\n"
     ]
    }
   ],
   "source": [
    "# TRAIN + EVALUATE: Logistic Regression baseline \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Modelo\n",
    "lr = LogisticRegression(\n",
    "    solver='liblinear',    \n",
    "    penalty='l2',\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "lr.fit(X_train_lr, y_train_lr)\n",
    "\n",
    "# Predicción en test (umbral 0.5 sobre probas)\n",
    "y_pred_lr = lr.predict(X_test_lr)\n",
    "\n",
    "# Métricas (positiva = True)\n",
    "recall_lr = recall_score(y_test_lr, y_pred_lr, pos_label=True)\n",
    "precision_lr = precision_score(y_test_lr, y_pred_lr, pos_label=True)\n",
    "\n",
    "print(\"Logistic Regression (baseline) — Test results\")\n",
    "print(f\" Recall  (positive class): {recall_lr:.4f}\")\n",
    "print(f\" Precision (positive class): {precision_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97619ab-600b-4924-8f47-aaab9e9fd4d3",
   "metadata": {},
   "source": [
    "# CELL 5: RANDOM FOREST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ac9842c-f076-42de-841c-e38a1394c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (baseline) — Test results\n",
      " Recall  (positive class): 0.1291\n",
      " Precision (positive class): 0.5912\n"
     ]
    }
   ],
   "source": [
    "# TRAIN + EVALUATE: Random Forest baseline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# Modelo\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample'  \n",
    ")\n",
    "\n",
    "# Fit\n",
    "rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# Predicción en test\n",
    "y_pred_rf = rf.predict(X_test_rf)\n",
    "\n",
    "# Métricas (positiva = True)\n",
    "recall_rf = recall_score(y_test_rf, y_pred_rf, pos_label=True)\n",
    "precision_rf = precision_score(y_test_rf, y_pred_rf, pos_label=True)\n",
    "\n",
    "print(\"Random Forest (baseline) — Test results\")\n",
    "print(f\" Recall  (positive class): {recall_rf:.4f}\")\n",
    "print(f\" Precision (positive class): {precision_rf:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-risk (conda)",
   "language": "python",
   "name": "model-risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
